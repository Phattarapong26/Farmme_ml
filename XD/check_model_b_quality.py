# -*- coding: utf-8 -*-
"""
‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û Model B
‡∏î‡∏π‡∏ß‡πà‡∏≤ train ‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
"""

import pickle
import json
from pathlib import Path

print("=" * 80)
print("üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û Model B")
print("=" * 80)

# 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå
print("\nüìÅ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå Model:")
model_files = [
    "model_b_xgboost.pkl",
    "model_b_temporal_gb.pkl",
    "model_b_logistic.pkl"
]

for model_file in model_files:
    path = Path(f"REMEDIATION_PRODUCTION/trained_models/{model_file}")
    if path.exists():
        size = path.stat().st_size
        print(f"   {model_file}: {size:,} bytes ({size/1024:.2f} KB)")
    else:
        print(f"   {model_file}: ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ")

# 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Evaluation Results
print("\nüìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô:")
eval_path = Path("REMEDIATION_PRODUCTION/trained_models/model_b_evaluation.json")
if eval_path.exists():
    with open(eval_path, 'r') as f:
        results = json.load(f)
    
    print(f"\n   Dataset Size:")
    print(f"   - Total: {results.get('dataset_size', {}).get('total', 'N/A')} samples")
    print(f"   - Train: {results.get('dataset_size', {}).get('train', 'N/A')} samples")
    print(f"   - Test: {results.get('dataset_size', {}).get('test', 'N/A')} samples")
    
    print(f"\n   Best Model: {results.get('best_model', 'N/A')}")
    
    for model_name, metrics in results.get('models', {}).items():
        print(f"\n   {model_name}:")
        print(f"   - F1: {metrics.get('f1', 'N/A'):.4f}")
        print(f"   - Precision: {metrics.get('precision', 'N/A'):.4f}")
        print(f"   - Recall: {metrics.get('recall', 'N/A'):.4f}")
        print(f"   - ROC-AUC: {metrics.get('roc_auc', 'N/A'):.4f}")
else:
    print("   ‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå evaluation")

# 3. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö Model
print("\nüß™ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏´‡∏•‡∏î Model:")
for model_file in model_files:
    path = Path(f"REMEDIATION_PRODUCTION/trained_models/{model_file}")
    if path.exists():
        try:
            with open(path, 'rb') as f:
                model = pickle.load(f)
            
            print(f"\n   {model_file}:")
            print(f"   - Type: {type(model).__name__}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö attributes
            if hasattr(model, 'model'):
                print(f"   - Has model: ‚úÖ")
                print(f"   - Model type: {type(model.model).__name__}")
            
            if hasattr(model, 'scaler'):
                print(f"   - Has scaler: ‚úÖ")
            
            # ‡∏•‡∏≠‡∏á predict
            import numpy as np
            X_test = np.random.rand(1, 8)  # 8 features
            
            try:
                if hasattr(model, 'predict'):
                    pred = model.predict(X_test)
                    print(f"   - Prediction: {pred[0]} ‚úÖ")
                else:
                    print(f"   - ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ predict method")
            except Exception as e:
                print(f"   - ‚ùå Prediction failed: {e}")
                
        except Exception as e:
            print(f"   ‚ùå ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")

# 4. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏õ‡∏±‡∏ç‡∏´‡∏≤
print("\n" + "=" * 80)
print("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
print("=" * 80)

# ‡∏≠‡πà‡∏≤‡∏ô evaluation results ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
if eval_path.exists():
    with open(eval_path, 'r') as f:
        results = json.load(f)
    
    total_samples = results.get('dataset_size', {}).get('total', 0)
    train_samples = results.get('dataset_size', {}).get('train', 0)
    
    print(f"\n1. ‡∏Ç‡∏ô‡∏≤‡∏î Dataset:")
    print(f"   Total: {total_samples} samples")
    print(f"   Train: {train_samples} samples")
    
    if total_samples < 10000:
        print(f"   ‚ö†Ô∏è Dataset ‡πÄ‡∏•‡πá‡∏Å! (< 10,000 samples)")
        print(f"   ‚Üí Model train ‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢")
    else:
        print(f"   ‚úÖ Dataset ‡∏Ç‡∏ô‡∏≤‡∏î‡∏û‡∏≠‡πÉ‡∏ä‡πâ")
    
    print(f"\n2. ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Features:")
    print(f"   Features: 8 features")
    print(f"   ‚ö†Ô∏è Features ‡∏ô‡πâ‡∏≠‡∏¢! (Model A ‡πÉ‡∏ä‡πâ 19 features)")
    print(f"   ‚Üí Model train ‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏û‡∏£‡∏≤‡∏∞ features ‡∏ô‡πâ‡∏≠‡∏¢")
    
    print(f"\n3. Algorithm:")
    best_model = results.get('best_model', '')
    if 'logistic' in best_model.lower():
        print(f"   Best: Logistic Regression")
        print(f"   ‚ö†Ô∏è Algorithm ‡∏á‡πà‡∏≤‡∏¢! (Linear model)")
        print(f"   ‚Üí Train ‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô linear model")
    
    print(f"\n4. Performance:")
    best_metrics = results.get('models', {}).get(best_model, {})
    f1 = best_metrics.get('f1', 0)
    recall = best_metrics.get('recall', 0)
    
    print(f"   F1: {f1:.4f}")
    print(f"   Recall: {recall:.4f}")
    
    if recall >= 0.99:
        print(f"   ‚ö†Ô∏è Recall ‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥! (= {recall:.4f})")
        print(f"   ‚Üí ‡∏≠‡∏≤‡∏à overfit ‡∏´‡∏£‡∏∑‡∏≠ data leakage")
    
    if f1 > 0.85:
        print(f"   ‚ö†Ô∏è F1 ‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥! (= {f1:.4f})")
        print(f"   ‚Üí ‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö data leakage")

print("\n" + "=" * 80)
print("üí° ‡∏™‡∏£‡∏∏‡∏õ:")
print("=" * 80)
print("""
Model B train ‡πÄ‡∏£‡πá‡∏ß‡πÄ‡∏û‡∏£‡∏≤‡∏∞:
1. Dataset ‡πÄ‡∏•‡πá‡∏Å (6,226 samples vs Model A ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ 1.4M samples)
2. Features ‡∏ô‡πâ‡∏≠‡∏¢ (8 features vs Model A ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ 19 features)
3. Algorithm ‡∏á‡πà‡∏≤‡∏¢ (Logistic Regression ‡πÄ‡∏õ‡πá‡∏ô linear model)

‚ö†Ô∏è ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö:
1. Recall = 1.0000 (100%) ‚Üí ‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢ data leakage
2. F1 = 0.8683 ‡∏™‡∏π‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
3. Dataset ‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

‚úÖ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:
1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö data leakage (features ‡∏ó‡∏µ‡πà‡∏£‡∏±‡πà‡∏ß‡πÑ‡∏´‡∏•)
2. ‡πÉ‡∏ä‡πâ dataset ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏∂‡πâ‡∏ô
3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
""")
